{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d35f466a-c0a5-451b-84f6-4bb962769e29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "import random # H2O 초기화 시 포트 번호 충돌 방지를 위해 사용\n",
    "\n",
    "import mlflow\n",
    "import mlflow.h2o# H2O 모델을 MLflow에 로깅하기 위한 H2O Flavor\n",
    "\n",
    "from mlflow.models.signature import infer_signature \n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c96f565-1fbe-4280-a0fe-0c0458f3f2b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. CSV 데이터 불러오기\n",
    "# 데이터 경로를 실제 환경에 맞게 수정해주세요.\n",
    "csv_path = '/Volumes/project/default/project/UHI_data_test.csv/'\n",
    "df = spark.read.option(\"header\", \"true\").csv(csv_path)\n",
    "\n",
    "print(\"--- 원본 Spark DataFrame 스키마 ---\")\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7493f9f8-e4d2-4eb7-9021-ea52ac8cc3bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. 데이터 타입 변환 (df_processed 생성)\n",
    "# H2O AutoML이 datetime 타입의 timestamp를 인식하도록 cast 합니다.\n",
    "df_processed = df.withColumn(\"green_rate\", col(\"green_rate\").cast(\"double\")) \\\n",
    "                  .withColumn(\"Building_Density\", col(\"Building_Density\").cast(\"double\")) \\\n",
    "                  .withColumn(\"car_registration_count\", col(\"car_registration_count\").cast(\"long\")) \\\n",
    "                  .withColumn(\"population_density\", col(\"population_density\").cast(\"double\")) \\\n",
    "                  .withColumn(\"avg_km_per_road_km\", col(\"avg_km_per_road_km\").cast(\"double\")) \\\n",
    "                  .withColumn(\"UHII\", col(\"UHII\").cast(\"double\")) \\\n",
    "                  .withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\")) \\\n",
    "                  .withColumn(\"suburban_temp_current\", col(\"suburban_temp_current\").cast(\"double\"))\n",
    "\n",
    "print(\"\\n--- 타입 변환 후 Spark DataFrame 스키마 ---\")\n",
    "df_processed.printSchema()\n",
    "df_processed.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "464d493f-920a-44fe-ac2b-efc17c6e6a45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Spark DataFrame을 Pandas DataFrame으로 변환\n",
    "# H2O는 Pandas DataFrame 또는 H2OFrame을 입력으로 받습니다.\n",
    "# 대규모 데이터셋의 경우 메모리 부족에 주의해야 합니다.\n",
    "try:\n",
    "    pandas_df = df_processed.toPandas()\n",
    "    print(f\"\\nSpark DataFrame을 Pandas DataFrame으로 변환 완료. 크기: {pandas_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Pandas DataFrame 변환 중 오류 발생: {e}\")\n",
    "    print(\"데이터셋이 너무 커서 메모리 부족이 발생했을 수 있습니다. 샘플링을 고려하세요.\")\n",
    "    # 예: pandas_df = df_processed.sample(fraction=0.1, seed=42).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b544535f-9d01-4b88-b5e5-80774306fb42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. H2O 초기화\n",
    "# Databricks에서 H2O를 초기화할 때 포트 충돌이 발생할 수 있으므로, 랜덤 포트를 사용하거나 특정 포트를 지정하는 것이 좋습니다.\n",
    "# cluster_mode=True 설정은 H2O를 Spark 클러스터에서 실행합니다. (권장)\n",
    "# nthreads=-1은 사용 가능한 모든 코어를 사용하겠다는 의미입니다.\n",
    "try:\n",
    "    h2o.init(\n",
    "        # ip=\"localhost\", # 로컬 IP 주소 지정 (선택 사항)\n",
    "        port=random.randint(54321, 65535), # 랜덤 포트 사용\n",
    "        nthreads=-1, # 사용 가능한 모든 스레드 사용\n",
    "        min_mem_size=\"4G\", # H2O에 할당할 최소 메모리 크기 (클러스터 환경에 맞게 조정)\n",
    "        # spark_session=spark, # SparkSession 지정 (Spark 클러스터에서 H2O 실행 시)\n",
    "        # strict_version_check=False # H2O 버전 체크 비활성화 (환경 문제시)\n",
    "    )\n",
    "    print(\"\\nH2O Flow UI: %s\" % h2o.cluster().get_web_ui())\n",
    "except Exception as e:\n",
    "    print(f\"H2O 초기화 중 오류 발생: {e}\")\n",
    "    print(\"H2O 클러스터가 이미 실행 중이거나 포트 충돌이 발생했을 수 있습니다.\")\n",
    "    print(\"h2o.shutdown() 후 다시 시도하거나, 다른 포트 번호를 사용해보세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fc81ef47-f2e7-4f93-a0b2-19e9b3676775",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. Pandas DataFrame을 H2OFrame으로 변환\n",
    "h2o_frame = h2o.H2OFrame(pandas_df)\n",
    "\n",
    "print(\"\\nH2OFrame 정보:\")\n",
    "h2o_frame.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "610b7766-897f-4f4a-b3f5-96178f38e437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7. 예측 대상 (y) 및 피처 (x) 정의\n",
    "y = 'UHII' # 예측하려는 컬럼\n",
    "x = [col for col in h2o_frame.columns if col != y]\n",
    "\n",
    "# H2OFrame의 컬럼 타입을 확인하는 올바른 방법은 .types 딕셔너리를 사용하는 것입니다.\n",
    "timestamp_col_type = h2o_frame.types.get('timestamp')\n",
    "\n",
    "print(f\"\\n'{y}'는 예측 대상입니다.\")\n",
    "print(f\"사용될 피처들 ({len(x)}개): {x}\")\n",
    "print(f\"H2OFrame의 'timestamp' 컬럼 타입: {timestamp_col_type}\") # 올바른 타입 출력\n",
    "\n",
    "# 이제 이 'timestamp_col_type' 변수를 사용하여 조건을 확인합니다.\n",
    "if timestamp_col_type != 'time':\n",
    "    print(\"경고: 'timestamp' 컬럼이 'time' 타입으로 인식되지 않았습니다. 변환을 다시 확인하거나 데이터 형식을 점검하세요.\")\n",
    "    # 만약 여전히 'time'이 아니라면, 다음 줄의 주석을 해제하여 강제로 'time' 타입으로 변환 시도\n",
    "    # h2o_frame['timestamp'] = h2o_frame['timestamp'].as_time()\n",
    "    # print(f\"강제 변환 후 'timestamp' 컬럼 타입: {h2o_frame.types.get('timestamp')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8378fe14-2e3e-4707-bc93-bf9dee37e7d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 8. AutoML 모델 학습 설정 및 실행\n",
    "# max_runtime_secs: 최대 실행 시간 (초). 시간 부족 시 모델 수가 적을 수 있습니다.\n",
    "# max_models: 최대 훈련할 모델 수.\n",
    "# seed: 재현성을 위한 시드 값.\n",
    "# sort_metric: 리더보드를 정렬하고 최적 모델을 선택할 때 사용할 평가 지표. (회귀: rmse, mae, rmsle, mean_residual_deviance)\n",
    "# exclude_algos: 특정 알고리즘 제외 (선택 사항).\n",
    "# include_algos: 특정 알고리즘만 포함 (선택 사항).\n",
    "# nfolds: 교차 검증 폴드 수.\n",
    "# verbosity: 상세 출력 수준 (debug, info, warn, error).\n",
    "\n",
    "aml = H2OAutoML(\n",
    "    max_runtime_secs=1800,  # 예: 1시간 (3600초) 동안 실행\n",
    "    max_models=40,         # 예: 최대 20개의 모델 훈련\n",
    "    seed=42,                # 재현성을 위한 시드\n",
    "    sort_metric=\"rmse\",     # 회귀 문제이므로 RMSE 사용\n",
    "    # exclude_algos=[\"DeepLearning\", \"GLM\"], # 특정 알고리즘 제외 예시\n",
    "    # nfolds=5, # 교차 검증을 5-fold로 설정 (선택 사항, 기본값은 자동으로 설정될 수 있음)\n",
    "    # verbosity=\"info\", # 상세 정보 출력\n",
    "    # project_name=\"UHI_Prediction\" # 프로젝트 이름 지정\n",
    ")\n",
    "\n",
    "print(\"\\n--- H2O AutoML 학습 시작 ---\")\n",
    "aml.train(x=x, y=y, training_frame=h2o_frame)\n",
    "\n",
    "print(\"\\n--- H2O AutoML 학습 완료 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "908c6012-5151-4263-98ad-ddb29587ca1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 9. 리더보드 확인 (최고 성능 모델 목록)\n",
    "leaderboard = aml.leaderboard\n",
    "print(\"\\n--- AutoML Leaderboard ---\")\n",
    "leaderboard.head(rows=10) # 상위 10개 모델 출력\n",
    "\n",
    "# 10. 최고 성능 모델 확인\n",
    "best_model = aml.leader\n",
    "print(f\"\\n최고 성능 모델: {best_model.model_id}\")\n",
    "\n",
    "# 모델 성능 평가 (학습 데이터 기준)\n",
    "print(f\"\\n--- 최고 모델 ({best_model.model_id})의 학습 데이터 기준 성능 ---\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {best_model.rmse(train=True)}\")\n",
    "print(f\"R2 (R-squared): {best_model.r2(train=True)}\")\n",
    "print(f\"MAE (Mean Absolute Error): {best_model.mae(train=True)}\")\n",
    "print(f\"RMSLE (Root Mean Squared Logarithmic Error): {best_model.rmsle(train=True)}\") # 필요한 경우 사용\n",
    "print(f\"MRD (Mean Residual Deviance): {best_model.mean_residual_deviance(train=True)}\")\n",
    "\n",
    "\n",
    "# 만약 검증 데이터를 분리했다면:\n",
    "# print(f\"최고 모델 ({best_model.model_id})의 검증 데이터 RMSE: {best_model.rmse(valid=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c6f284-6fa3-46ba-bb2e-4548e119e7bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 피쳐 중요도\n",
    "# (이전 코드에서 H2OAutoML 학습 완료 후 best_model 객체가 있다고 가정)\n",
    "# best_model = aml.leader\n",
    "\n",
    "# 피처 중요도 테이블 가져오기\n",
    "varimp_df = best_model.varimp(use_pandas=True)\n",
    "\n",
    "print(\"\\n--- 최고 모델의 피처 중요도 (상위 10개) ---\")\n",
    "# Importance, Percentage, Cumulative Sum 컬럼이 포함됩니다.\n",
    "print(varimp_df.head(10))\n",
    "\n",
    "# 전체 피처 중요도를 보고 싶다면\n",
    "# print(varimp_df)\n",
    "\n",
    "# 중요도 순으로 정렬되어 있으므로, 처음 몇 개만 봐도 주요 피처를 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1447eb85-5431-40d7-87bd-8a950d3aa82b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "h2o_df=h2o_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d249ac94-56c3-4f2d-b150-f5989b27c532",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "save_path = h2o.save_model(model=best_model, path=\"/dbfs/tmp/mymodel\", force=True)\n",
    "print(f\"모델 저장 경로: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7823951-3427-4271-8aee-ec5802931157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_path=\"/dbfs/tmp/mymodel/XGBoost_1_AutoML_2_20250605_80504\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb620b30-4fa2-48d7-8dbf-8ce9451edf3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "best_model = h2o.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cea68368-3326-495e-8db2-a0918b2baa07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c9864e6-da7a-4aa2-b2c2-a1815264fc30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측 테스트\n",
    "\n",
    "area = 'Gangnam-gu'\n",
    "val1 = 0.4\n",
    "val2 = 1.3\n",
    "val3 = 257346\n",
    "val4 = 14258.6\n",
    "val5 = 20753.1\n",
    "\n",
    "new_data_spark_df_raw = spark.createDataFrame([\n",
    "    (area, val1, val2, val3, val4, val5, '2024-06-09T12:00:00.000Z', 26.0),\n",
    "    (area, val1, val2, val3, val4, val5, '2024-06-09T15:00:00.000Z', 20.9),\n",
    "    (area, val1, val2, val3, val4, val5, '2024-06-09T18:00:00.000Z', 20.9),\n",
    "    (area, val1, val2, val3, val4, val5, '2024-06-09T21:00:00.000Z', 20.9),\n",
    "\n",
    "], schema=[\n",
    "    'District', 'green_rate', 'Building_Density', 'car_registration_count',\n",
    "    'population_density', 'avg_km_per_road_km', 'timestamp', 'suburban_temp_current'\n",
    "])\n",
    "\n",
    "# 2. 학습 데이터와 동일한 Spark DataFrame 전처리 적용\n",
    "# 여기서 timestamp 컬럼을 Spark의 timestamp 타입으로 캐스팅합니다.\n",
    "new_data_spark_df_processed = new_data_spark_df_raw.withColumn(\"green_rate\", col(\"green_rate\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"Building_Density\", col(\"Building_Density\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"car_registration_count\", col(\"car_registration_count\").cast(\"long\")) \\\n",
    "                                                     .withColumn(\"population_density\", col(\"population_density\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"avg_km_per_road_km\", col(\"avg_km_per_road_km\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\")) \\\n",
    "                                                     .withColumn(\"suburban_temp_current\", col(\"suburban_temp_current\").cast(\"double\"))\n",
    "\n",
    "print(\"\\n--- 예측할 새로운 Spark DataFrame (전처리 후) ---\")\n",
    "\n",
    "# 3. Spark DataFrame을 Pandas DataFrame으로 변환\n",
    "new_data_pandas_df = new_data_spark_df_processed.toPandas()\n",
    "\n",
    "# Pandas에서 datetime 타입으로 이미 잘 변환되었는지 확인\n",
    "print(\"\\n--- 예측할 새로운 Pandas DataFrame ---\")\n",
    "display(new_data_pandas_df)\n",
    "print(\"\\nTimestamp 컬럼 타입 (Pandas):\", new_data_pandas_df['timestamp'].dtype)\n",
    "\n",
    "\n",
    "# 4. Pandas DataFrame을 H2OFrame으로 변환 (예측 데이터)\n",
    "# 학습 시와 동일한 방식으로 H2O가 'timestamp' 컬럼을 'time' 타입으로 자동 추론하기를 기대합니다.\n",
    "new_h2o_frame = h2o.H2OFrame(new_data_pandas_df)\n",
    "\n",
    "\n",
    "# 5. H2OFrame의 'timestamp' 컬럼 타입 확인\n",
    "# H2O가 'time' 타입으로 잘 인식했는지 최종 확인합니다.\n",
    "h2o_frame_timestamp_type = new_h2o_frame.types.get('timestamp')\n",
    "#print(f\"\\n변환 후 예측 데이터 'timestamp' 컬럼 H2O 타입: {h2o_frame_timestamp_type}\")\n",
    "\n",
    "if h2o_frame_timestamp_type != 'time':\n",
    "    print(\"경고: 'timestamp' 컬럼이 'time' 타입으로 인식되지 않았습니다. 모델 예측에 문제가 발생할 수 있습니다.\")\n",
    "\n",
    "# 6. 최고 성능 모델로 예측 수행\n",
    "predictions = best_model.predict(new_h2o_frame)\n",
    "\n",
    "# 7. 예측 결과를 Pandas DataFrame으로 변환하여 원본 데이터와 함께 보기\n",
    "predictions_df = predictions.as_data_frame()\n",
    "result_df = pd.concat([new_data_pandas_df, predictions_df], axis=1)\n",
    "\n",
    "\n",
    "print(\"\\n--- 입력 데이터와 최종 UHII 예측 결과 ---\")\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3d2fecd0-a033-451d-bc10-d1b9f2788862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 예측 - 25개구 차이 확인\n",
    "\n",
    "seoul_districts = [\n",
    "    'Gangnam-gu', 'Gangdong-gu', 'Gangbuk-gu', 'Gangseo-gu',\n",
    "    'Gwanak-gu', 'Gwangjin-gu', 'Guro-gu', 'Geumcheon-gu',\n",
    "    'Nowon-gu', 'Dobong-gu', 'Dongdaemun-gu', 'Dongjak-gu',\n",
    "    'Mapo-gu', 'Seodaemun-gu', 'Seocho-gu', 'Seongdong-gu',\n",
    "    'Seongbuk-gu', 'Songpa-gu', 'Yangcheon-gu', 'Yeongdeungpo-gu',\n",
    "    'Yongsan-gu', 'Eunpyeong-gu', 'Jongno-gu', 'Jung-gu', 'Jungnang-gu'\n",
    "]\n",
    "\n",
    "# 모든 구에 적용할 공통 조건 값 (수동으로 설정)\n",
    "# 이 값들은 예시이며, 특정 시나리오에 맞게 조정할 수 있습니다.\n",
    "common_green_rate = 0.45          # 중간 정도의 녹지율\n",
    "common_building_density = 1.3     # 중간 정도의 건물 밀도\n",
    "common_car_registration_count = 100000 # 일반적인 차량 등록 대수\n",
    "common_population_density = 18000.0 # 일반적인 인구 밀도\n",
    "common_avg_km_per_road_km = 8000.0  # 일반적인 도로 km당 주행 거리\n",
    "common_timestamp = '2025-08-01T16:00:00.000Z' # 여름 오후 4시\n",
    "common_suburban_temp_current = 23.5 # 여름철 다소 더운 외곽 온도\n",
    "\n",
    "# 25개 구 각각에 대해 동일한 수치형 조건과 시간/외곽 온도를 가진 데이터를 생성\n",
    "data_rows = []\n",
    "for district in seoul_districts:\n",
    "    data_rows.append((\n",
    "        district,\n",
    "        common_green_rate,\n",
    "        common_building_density,\n",
    "        common_car_registration_count,\n",
    "        common_population_density,\n",
    "        common_avg_km_per_road_km,\n",
    "        common_timestamp,\n",
    "        common_suburban_temp_current\n",
    "    ))\n",
    "\n",
    "# new_data_spark_df_raw 변수에 위에서 생성한 data_rows를 할당합니다.\n",
    "new_data_spark_df_raw = spark.createDataFrame(data_rows, schema=[\n",
    "    'District', 'green_rate', 'Building_Density', 'car_registration_count',\n",
    "    'population_density', 'avg_km_per_road_km', 'timestamp', 'suburban_temp_current'\n",
    "])\n",
    "\n",
    "# 2. 학습 데이터와 동일한 Spark DataFrame 전처리 적용\n",
    "# 이 부분은 변경되지 않습니다.\n",
    "new_data_spark_df_processed = new_data_spark_df_raw.withColumn(\"green_rate\", col(\"green_rate\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"Building_Density\", col(\"Building_Density\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"car_registration_count\", col(\"car_registration_count\").cast(\"long\")) \\\n",
    "                                                     .withColumn(\"population_density\", col(\"population_density\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"avg_km_per_road_km\", col(\"avg_km_per_road_km\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\")) \\\n",
    "                                                     .withColumn(\"suburban_temp_current\", col(\"suburban_temp_current\").cast(\"double\"))\n",
    "\n",
    "# 3. Spark DataFrame을 Pandas DataFrame으로 변환\n",
    "# 이 부분은 변경되지 않습니다.\n",
    "new_data_pandas_df = new_data_spark_df_processed.toPandas()\n",
    "\n",
    "print(\"\\n--- 예측할 새로운 Pandas DataFrame ---\")\n",
    "display(new_data_pandas_df)\n",
    "print(\"\\nTimestamp 컬럼 타입 (Pandas):\", new_data_pandas_df['timestamp'].dtype)\n",
    "\n",
    "# 4. Pandas DataFrame을 H2OFrame으로 변환 (예측 데이터)\n",
    "# best_model 객체는 이전에 학습이 완료되어 정의되어 있어야 합니다.\n",
    "# 이 부분은 변경되지 않습니다.\n",
    "new_h2o_frame = h2o.H2OFrame(new_data_pandas_df)\n",
    "\n",
    "# 5. H2OFrame의 'timestamp' 컬럼 타입 확인\n",
    "# 이 부분은 변경되지 않습니다.\n",
    "h2o_frame_timestamp_type = new_h2o_frame.types.get('timestamp')\n",
    "print(f\"\\n변환 후 예측 데이터 'timestamp' 컬럼 H2O 타입: {h2o_frame_timestamp_type}\")\n",
    "\n",
    "if h2o_frame_timestamp_type != 'time':\n",
    "    print(\"경고: 'timestamp' 컬럼이 'time' 타입으로 인식되지 않았습니다. 모델 예측에 문제가 발생할 수 있습니다.\")\n",
    "\n",
    "# 6. 최고 성능 모델로 예측 수행\n",
    "predictions = best_model.predict(new_h2o_frame)\n",
    "\n",
    "# 7. 예측 결과를 Pandas DataFrame으로 변환하여 원본 데이터와 함께 보기\n",
    "predictions_df = predictions.as_data_frame()\n",
    "result_df = pd.concat([new_data_pandas_df, predictions_df], axis=1)\n",
    "\n",
    "print(\"\\n--- 입력 데이터와 최종 UHII 예측 결과 ---\")\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b7fd7485-e61a-4304-8ab0-d8ae713315d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 예측 - 정적피쳐 확인\n",
    "\n",
    "# --- 고정할 구와 시간/외곽 온도 설정 ---\n",
    "target_district = 'Gangbuk-gu'\n",
    "fixed_timestamp = '2025-06-01T16:00:00.000Z' # 여름 오후 4시\n",
    "fixed_suburban_temp_current = 23.5 # 여름철 다소 시원한 외곽 온도\n",
    "\n",
    "# --- 고정할 다른 변수들의 기준값 설정 (중구의 일반적인 특성 또는 임의의 기준) ---\n",
    "# 여기서는 예시로 임의의 값을 사용하지만, 실제 데이터의 평균을 사용해도 좋습니다.\n",
    "fixed_car_registration_count = 53324   # 중구 기준값\n",
    "fixed_population_density = 13174.096 # 중구 기준값\n",
    "fixed_avg_km_per_road_km = 14927.25044 # 중구 기준값\n",
    "\n",
    "# --- 다양한 시나리오별 녹지율 및 건물 밀도 설정 ---\n",
    "data_rows = []\n",
    "\n",
    "# 시나리오 1: 중구의 현재(또는 기준) 특성\n",
    "data_rows.append((\n",
    "    target_district,\n",
    "    0.255,   # 중구의 녹지율 기준\n",
    "    2.07,    # 중구의 건물 밀도 기준\n",
    "    fixed_car_registration_count,\n",
    "    fixed_population_density,\n",
    "    fixed_avg_km_per_road_km,\n",
    "    fixed_timestamp,\n",
    "    fixed_suburban_temp_current\n",
    "))\n",
    "\n",
    "# 시나리오 2: 녹지율을 낮게 (열섬 심화 예상)\n",
    "data_rows.append((\n",
    "    target_district,\n",
    "    0.1,     # 녹지율 매우 낮게\n",
    "    2.07,    # 건물 밀도 유지\n",
    "    fixed_car_registration_count,\n",
    "    fixed_population_density,\n",
    "    fixed_avg_km_per_road_km,\n",
    "    fixed_timestamp,\n",
    "    fixed_suburban_temp_current\n",
    "))\n",
    "\n",
    "# 시나리오 3: 녹지율을 높게 (열섬 완화 예상)\n",
    "data_rows.append((\n",
    "    target_district,\n",
    "    0.5,     # 녹지율 높게\n",
    "    2.07,    # 건물 밀도 유지\n",
    "    fixed_car_registration_count,\n",
    "    fixed_population_density,\n",
    "    fixed_avg_km_per_road_km,\n",
    "    fixed_timestamp,\n",
    "    fixed_suburban_temp_current\n",
    "))\n",
    "\n",
    "# 시나리오 4: 건물 밀도를 낮게 (열섬 완화 예상)\n",
    "data_rows.append((\n",
    "    target_district,\n",
    "    0.255,   # 녹지율 유지\n",
    "    1.0,     # 건물 밀도 낮게\n",
    "    fixed_car_registration_count,\n",
    "    fixed_population_density,\n",
    "    fixed_avg_km_per_road_km,\n",
    "    fixed_timestamp,\n",
    "    fixed_suburban_temp_current\n",
    "))\n",
    "\n",
    "# 시나리오 5: 건물 밀도를 높게 (열섬 심화 예상)\n",
    "data_rows.append((\n",
    "    target_district,\n",
    "    0.255,   # 녹지율 유지\n",
    "    2.8,     # 건물 밀도 높게\n",
    "    fixed_car_registration_count,\n",
    "    fixed_population_density,\n",
    "    fixed_avg_km_per_road_km,\n",
    "    fixed_timestamp,\n",
    "    fixed_suburban_temp_current\n",
    "))\n",
    "\n",
    "# 시나리오 6: 녹지율 높고, 건물 밀도 낮게 (열섬 최적 완화 시나리오)\n",
    "data_rows.append((\n",
    "    target_district,\n",
    "    0.6,     # 녹지율 매우 높게\n",
    "    0.8,     # 건물 밀도 매우 낮게\n",
    "    fixed_car_registration_count,\n",
    "    fixed_population_density,\n",
    "    fixed_avg_km_per_road_km,\n",
    "    fixed_timestamp,\n",
    "    fixed_suburban_temp_current\n",
    "))\n",
    "\n",
    "# 시나리오 7: 녹지율 낮고, 건물 밀도 높게 (열섬 최악 심화 시나리오)\n",
    "data_rows.append((\n",
    "    target_district,\n",
    "    0.05,    # 녹지율 매우 낮게\n",
    "    3.0,     # 건물 밀도 매우 높게\n",
    "    fixed_car_registration_count,\n",
    "    fixed_population_density,\n",
    "    fixed_avg_km_per_road_km,\n",
    "    fixed_timestamp,\n",
    "    fixed_suburban_temp_current\n",
    "))\n",
    "\n",
    "\n",
    "# --- 오직 new_data_spark_df_raw 변수에 위에서 생성한 data_rows를 할당합니다. ---\n",
    "new_data_spark_df_raw = spark.createDataFrame(data_rows, schema=[\n",
    "    'District', 'green_rate', 'Building_Density', 'car_registration_count',\n",
    "    'population_density', 'avg_km_per_road_km', 'timestamp', 'suburban_temp_current'\n",
    "])\n",
    "# --- 변경 끝 ---\n",
    "\n",
    "print(\"--- 단일 구(중구)의 고정 변수 변화에 따른 Raw Spark DataFrame ---\")\n",
    "new_data_spark_df_raw.show(truncate=False)\n",
    "new_data_spark_df_raw.printSchema()\n",
    "\n",
    "# --- 이후의 전처리 및 예측 파이프라인은 이전과 동일하게 연결됩니다 ---\n",
    "\n",
    "# 2. 학습 데이터와 동일한 Spark DataFrame 전처리 적용\n",
    "new_data_spark_df_processed = new_data_spark_df_raw.withColumn(\"green_rate\", col(\"green_rate\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"Building_Density\", col(\"Building_Density\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"car_registration_count\", col(\"car_registration_count\").cast(\"long\")) \\\n",
    "                                                     .withColumn(\"population_density\", col(\"population_density\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"avg_km_per_road_km\", col(\"avg_km_per_road_km\").cast(\"double\")) \\\n",
    "                                                     .withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\")) \\\n",
    "                                                     .withColumn(\"suburban_temp_current\", col(\"suburban_temp_current\").cast(\"double\"))\n",
    "\n",
    "print(\"\\n--- 예측할 새로운 Spark DataFrame (전처리 후) ---\")\n",
    "new_data_spark_df_processed.show(truncate=False)\n",
    "new_data_spark_df_processed.printSchema()\n",
    "\n",
    "\n",
    "# 3. Spark DataFrame을 Pandas DataFrame으로 변환\n",
    "new_data_pandas_df = new_data_spark_df_processed.toPandas()\n",
    "\n",
    "print(\"\\n--- 예측할 새로운 Pandas DataFrame ---\")\n",
    "display(new_data_pandas_df)\n",
    "print(\"\\nTimestamp 컬럼 타입 (Pandas):\", new_data_pandas_df['timestamp'].dtype)\n",
    "\n",
    "\n",
    "# 4. Pandas DataFrame을 H2OFrame으로 변환 (예측 데이터)\n",
    "# best_model 객체는 이전에 학습이 완료되어 정의되어 있어야 합니다.\n",
    "new_h2o_frame = h2o.H2OFrame(new_data_pandas_df)\n",
    "\n",
    "\n",
    "# 5. H2OFrame의 'timestamp' 컬럼 타입 확인\n",
    "h2o_frame_timestamp_type = new_h2o_frame.types.get('timestamp')\n",
    "print(f\"\\n변환 후 예측 데이터 'timestamp' 컬럼 H2O 타입: {h2o_frame_timestamp_type}\")\n",
    "\n",
    "if h2o_frame_timestamp_type != 'time':\n",
    "    print(\"경고: 'timestamp' 컬럼이 'time' 타입으로 인식되지 않았습니다. 모델 예측에 문제가 발생할 수 있습니다.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- 예측할 새로운 H2OFrame 정보 ---\")\n",
    "new_h2o_frame.show_summary()\n",
    "\n",
    "\n",
    "# 6. 최고 성능 모델로 예측 수행\n",
    "predictions = best_model.predict(new_h2o_frame)\n",
    "\n",
    "\n",
    "print(\"\\n--- 예측 결과 ---\")\n",
    "display(predictions.head(len(new_data_pandas_df))) # 모든 예측 결과 표시\n",
    "\n",
    "\n",
    "# 7. 예측 결과를 Pandas DataFrame으로 변환하여 원본 데이터와 함께 보기\n",
    "predictions_df = predictions.as_data_frame()\n",
    "result_df = pd.concat([new_data_pandas_df, predictions_df], axis=1)\n",
    "\n",
    "\n",
    "print(\"\\n--- 입력 데이터와 최종 UHII 예측 결과 ---\")\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0b6a2723-e55c-46e8-b5b3-e679b12b72ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 예측 - 녹지율 변화에 따른 특정 구 예측\n",
    "\n",
    "# 녹지율을 변화시킨 예측 데이터 생성\n",
    "new_data_spark_df_raw_scenario2_green_rate = spark.createDataFrame([\n",
    "    ('Jung-gu', 0.1,  jung_gu_avg_features['Building_Density'], jung_gu_avg_features['car_registration_count'], jung_gu_avg_features['population_density'], jung_gu_avg_features['avg_km_per_road_km'], TARGET_TIMESTAMP_STR, TARGET_SUBURBAN_TEMP), # 녹지율 매우 낮게 (예: 10%)\n",
    "    ('Jung-gu', jung_gu_avg_features['green_rate'], jung_gu_avg_features['Building_Density'], jung_gu_avg_features['car_registration_count'], jung_gu_avg_features['population_density'], jung_gu_avg_features['avg_km_per_road_km'], TARGET_TIMESTAMP_STR, TARGET_SUBURBAN_TEMP), # 현재 중구 평균 녹지율\n",
    "    ('Jung-gu', 0.4,  jung_gu_avg_features['Building_Density'], jung_gu_avg_features['car_registration_count'], jung_gu_avg_features['population_density'], jung_gu_avg_features['avg_km_per_road_km'], TARGET_TIMESTAMP_STR, TARGET_SUBURBAN_TEMP), # 녹지율 중간 수준으로 높게 (예: 40%)\n",
    "    ('Jung-gu', 0.6,  jung_gu_avg_features['Building_Density'], jung_gu_avg_features['car_registration_count'], jung_gu_avg_features['population_density'], jung_gu_avg_features['avg_km_per_road_km'], TARGET_TIMESTAMP_STR, TARGET_SUBURBAN_TEMP)  # 녹지율 매우 높게 (예: 60%)\n",
    "], schema=[\n",
    "    'District', 'green_rate', 'Building_Density', 'car_registration_count',\n",
    "    'population_density', 'avg_km_per_road_km', 'timestamp', 'suburban_temp_current'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6a117c71-4611-40e5-83c8-52aaa7e18207",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 모두 실행시 모델 등록 오류 발생 방지용 중단\n",
    "raise Exception(\"여기서 중단합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea34e9aa-2e8c-4afc-aa63-1ab11dc8af34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 새 모델 등록 (재실행 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5cb65086-844e-4d4b-a7f5-d1f076258645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 모델 로깅\n",
    "# 1. 모델 시그니처를 위한 샘플 입력 데이터 준비\n",
    "# `input_example`은 Pandas DataFrame이어야 하며, H2O 모델의 학습 컬럼 스키마와 정확히 일치해야 합니다.\n",
    "# 제공해주신 `new_data_spark_df_raw`의 컬럼들을 사용합니다.\n",
    "sample_input = pd.DataFrame([\n",
    "    ('Jungnang-gu', 0.364, 1.178, 113569, 21597.946, 8848.239521, '2020-08-01T18:00:00.000Z', 20.79),\n",
    "    ('Dobong-gu', 0.569, 0.764, 96298, 15852.833, 5277.944143, '2020-08-01T18:00:00.000Z', 20.79),\n",
    "    ('Jung-gu', 0.255, 2.07, 53324, 13174.096, 14927.25044, '2020-08-01T18:00:00.000Z', 20.79)\n",
    "], columns=[\n",
    "    'District', 'green_rate', 'Building_Density', 'car_registration_count',\n",
    "    'population_density', 'avg_km_per_road_km', 'timestamp', 'suburban_temp_current'\n",
    "])\n",
    "\n",
    "\n",
    "# 2. H2O 모델의 예측 결과를 사용하여 출력 스키마 추론\n",
    "# H2O 모델의 predict 메서드는 H2OFrame을 반환하므로, 이를 Pandas DataFrame으로 변환해야 합니다.\n",
    "# 분류 모델의 경우 일반적으로 predict()는 확률(p0, p1 등)과 예측 레이블(predict)을 반환합니다.\n",
    "# 실제 모델의 예측 결과 형태를 확인하여 `sample_output`을 구성해야 합니다.\n",
    "try:\n",
    "    # sample_input (Pandas DataFrame)을 H2OFrame으로 변환하여 predict 호출\n",
    "    sample_output_hf = best_model.predict(h2o.H2OFrame(sample_input))\n",
    "    sample_output = sample_output_hf.as_data_frame()\n",
    "except Exception as e:\n",
    "    print(f\"Error predicting with H2O model for signature inference: {e}\")\n",
    "    print(\"Assuming a simple output for signature (e.g., single prediction column).\")\n",
    "    # 예외 발생 시, 최소한의 출력 스키마를 수동으로 가정\n",
    "    # 실제 H2O 모델의 출력 형태에 맞게 수정해야 합니다.\n",
    "    # 분류 모델이라면, 'predict' 컬럼과 'p0', 'p1' 등의 확률 컬럼이 있을 수 있습니다.\n",
    "    # H2O 분류 모델의 기본 출력은 'predict' (클래스 레이블) 및 'p0', 'p1' (확률) 입니다.\n",
    "    # 따라서 최소한 다음과 같이 구성해야 할 수도 있습니다.\n",
    "    sample_output = pd.DataFrame({\n",
    "        'predict': [0, 1],\n",
    "        'p0': [0.5, 0.5],\n",
    "        'p1': [0.5, 0.5]\n",
    "    })\n",
    "\n",
    "\n",
    "# 3. `infer_signature`를 사용하여 모델 시그니처 생성\n",
    "# `infer_signature(model_input, model_output)`\n",
    "signature = infer_signature(sample_input, sample_output)\n",
    "\n",
    "# MLflow experiment 설정\n",
    "mlflow.set_experiment(\"/Shared/H2O_AutoML_Deployment_Example\")\n",
    "\n",
    "# MLflow Run 시작\n",
    "with mlflow.start_run(run_name=\"H2O_AutoML_Best_Model_Log_With_Signature\") as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "\n",
    "    mlflow.h2o.log_model(\n",
    "        h2o_model=best_model,\n",
    "        artifact_path=\"h2o_automl_best_model\",\n",
    "        conda_env={\n",
    "            \"channels\": [\"defaults\", \"conda-forge\"],\n",
    "            \"dependencies\": [\n",
    "                \"python=3.9\", # 사용하고 있는 파이썬 버전으로 변경\n",
    "                \"pip\",\n",
    "                {\n",
    "                    \"pip\": [\n",
    "                        f\"h2o=={h2o.__version__}\", # 현재 설치된 H2O 버전 사용\n",
    "                        \"mlflow\",\n",
    "                        \"scikit-learn\", # H2O 모델이 scikit-learn 종속성을 가질 수 있음\n",
    "                        \"cloudpickle==2.0.0\", # MLflow 모델 서빙을 위해 특정 버전 필요할 수 있음\n",
    "                        \"pandas\" # 필요한 경우 추가\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        signature=signature, # <-- 이 부분이 수정된 핵심!\n",
    "        input_example=sample_input # input_example은 여전히 유용하므로 유지\n",
    "    )\n",
    "\n",
    "    print(f\"H2O best model logged to MLflow with signature at 'runs:/{run_id}/h2o_automl_best_model'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50fb0c39-ba1a-4e62-b830-40d6cefc6c7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "mlflow.h2o.log_model: H2O 모델을 MLflow 형식으로 로깅하는 핵심 함수입니다.\n",
    "\n",
    "h2o_model: 로깅할 H2O 모델 객체 (best_model).\n",
    "\n",
    "artifact_path: MLflow UI에서 이 모델이 저장될 artifacts 경로입니다. (mlruns/<run_id>/artifacts/<artifact_path>)\n",
    "conda_env: 매우 중요합니다. 이 conda_env는 MLflow 모델 엔드포인트가 모델을 로드하고 예측을 수행하는 데 필요한 Python 환경과 라이브러리 종속성을 정의합니다.\n",
    "\n",
    "H2O 버전을 모델을 학습시킨 버전과 정확히 일치시켜야 합니다.\n",
    "\n",
    "\n",
    "cloudpickle 버전도 특정 버전으로 고정하는 것이 모델 서빙에서 오류를 줄이는 데 도움이 됩니다.\n",
    "\n",
    "모델 예측에 필요한 다른 라이브러리(예: pandas)가 있다면 추가합니다.\n",
    "\n",
    "input_example: 모델의 입력 스키마를 정의하는 데 사용됩니다. 이는 모델 서빙 엔드포인트에서 요청 유효성 검사 및 문서화를 위해 유용합니다. 실제 모델의 입력 형태와 일치하는 Pandas DataFrame을 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "415070cd-464e-47e4-ac33-cf43a2cec89e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 이전 셀의 `run_id`와 `artifact_path`를 사용하여 모델 등록\n",
    "registered_model_name = \"H2O_AutoML_predictor_Model\" # 등록할 모델 이름\n",
    "\n",
    "model_uri = f\"runs:/{run_id}/h2o_automl_best_model\"\n",
    "registered_model = mlflow.register_model(\n",
    "    model_uri=model_uri,\n",
    "    name=registered_model_name\n",
    ")\n",
    "\n",
    "print(f\"Model registered as: {registered_model.name} version {registered_model.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a18139fc-3c8a-42fe-8db0-4d2de841abc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 기존 모델 재등록 (버전관리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3612191d-f324-473c-b6ea-0ae8fe265033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. 새로운 Run에서 모델 시그니처를 위한 샘플 입력 데이터 준비\n",
    "#    H2O 모델의 학습 컬럼 스키마와 정확히 일치해야 합니다.\n",
    "sample_input = pd.DataFrame([\n",
    "    ('Jungnang-gu', 0.364, 1.178, 113569, 21597.946, 8848.239521, '2020-08-01T18:00:00.000Z', 20.79)\n",
    "], columns=[\n",
    "    'District', 'green_rate', 'Building_Density', 'car_registration_count',\n",
    "    'population_density', 'avg_km_per_road_km', 'timestamp', 'suburban_temp_current'\n",
    "])\n",
    "\n",
    "# 2. H2O 모델의 예측 결과를 사용하여 출력 스키마 추론\n",
    "sample_output_hf = best_model.predict(h2o.H2OFrame(sample_input))\n",
    "sample_output = sample_output_hf.as_data_frame()\n",
    "signature = infer_signature(sample_input, sample_output)\n",
    "\n",
    "# MLflow experiment 설정 (이전과 동일)\n",
    "mlflow.set_experiment(\"/Shared/H2O_AutoML_Deployment_Example\")\n",
    "\n",
    "# 새로운 MLflow Run 시작\n",
    "with mlflow.start_run(run_name=\"H2O_AutoML_New_Version_Log\") as run:\n",
    "    new_run_id = run.info.run_id # 새로운 Run ID\n",
    "    print(f\"새로운 MLflow Run ID: {new_run_id}\")\n",
    "\n",
    "    mlflow.h2o.log_model(\n",
    "        h2o_model=best_model,\n",
    "        artifact_path=\"h2o_automl_best_model\",\n",
    "        conda_env={\n",
    "            \"channels\": [\"defaults\", \"conda-forge\"],\n",
    "            \"dependencies\": [\n",
    "                \"python=3.9\",\n",
    "                \"pip\",\n",
    "                {\"pip\": [f\"h2o=={h2o.__version__}\", \"mlflow\", \"scikit-learn\", \"cloudpickle==2.0.0\", \"pandas\"]}\n",
    "            ]\n",
    "        },\n",
    "        signature=signature,\n",
    "        input_example=sample_input\n",
    "    )\n",
    "    print(f\"새 모델이 Runs에 로깅되었습니다: 'runs:/{new_run_id}/h2o_automl_best_model'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cf8b8d0d-3d7b-4db0-9775-e88d824d7d56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 기존에 등록된 모델 이름과 동일하게 지정\n",
    "registered_model_name = \"H2O_AutoML_predictor_Model\"\n",
    "\n",
    "# 새로운 모델의 MLflow URI (위에서 생성된 new_run_id 사용)\n",
    "model_uri = f\"runs:/{new_run_id}/h2o_automl_best_model\"\n",
    "\n",
    "# 동일한 이름으로 register_model 호출\n",
    "# MLflow가 자동으로 다음 버전을 할당하여 등록합니다.\n",
    "registered_model_version = mlflow.register_model(\n",
    "    model_uri=model_uri,\n",
    "    name=registered_model_name\n",
    ")\n",
    "\n",
    "print(f\"모델 '{registered_model_name}'의 새로운 버전이 등록되었습니다: 버전 {registered_model_version.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1707725-2ff2-44ff-8089-b5fbf98df0ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "505b42df-6943-4557-b702-b62fc8215583",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 앙상블 (테스트) - 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6c42c79-66ba-46e0-9155-d147274a5cbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 정적 피처와 타겟 정의 ---\n",
    "static_features = [\n",
    "    'District', 'green_rate', 'Building_Density', 'car_registration_count',\n",
    "    'population_density', 'avg_km_per_road_km'\n",
    "]\n",
    "target_feature = 'UHII'\n",
    "\n",
    "# --- AutoML을 위한 H2OFrame 준비 (선택 사항: 명시적으로 static_features만 포함) ---\n",
    "# 이렇게 하면 AutoML이 불필요한 컬럼을 학습하지 않습니다.\n",
    "# 단, 원본 h2o_df에는 target_feature도 있어야 합니다.\n",
    "static_h2o_training_frame = h2o_frame[:, static_features + [target_feature]]\n",
    "\n",
    "\n",
    "# --- H2O AutoML 실행 (정적 피처만 사용하여) ---\n",
    "print(\"\\n--- 정적 피처만으로 H2O AutoML 학습 시작 ---\")\n",
    "# AutoML 객체 생성\n",
    "# max_runtime_secs: AutoML이 학습할 최대 시간 (초 단위). 적절히 설정 (예: 600초 = 10분)\n",
    "# seed: 재현성을 위한 시드\n",
    "# sort_metric: 리더보드를 정렬할 기준 (회귀에서는 'rmse'가 적합)\n",
    "static_automl_leaderboard = H2OAutoML(\n",
    "    max_runtime_secs=600, # 10분 동안 학습\n",
    "    seed=1234,\n",
    "    sort_metric=\"rmse\"\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "# x에는 정적 피처 리스트, y에는 타겟 피처 이름, training_frame에는 정적 피처와 타겟이 있는 H2OFrame\n",
    "static_automl_leaderboard.train(\n",
    "    x=static_features,\n",
    "    y=target_feature,\n",
    "    training_frame=static_h2o_training_frame\n",
    ")\n",
    "\n",
    "# 최적의 모델 (리더 모델) 가져오기\n",
    "best_static_model_from_automl = static_automl_leaderboard.leader\n",
    "\n",
    "print(\"\\n--- H2O AutoML 정적 피처 모델 리더보드 ---\")\n",
    "static_automl_leaderboard.leaderboard.as_data_frame()\n",
    "\n",
    "\n",
    "print(f\"\\n--- H2O AutoML로 찾은 최적의 정적 피처 모델: {best_static_model_from_automl.model_id} ---\")\n",
    "best_static_model_from_automl.show()\n",
    "print(f\"최적 Static Model RMSE (Cross-Validation / Leaderboard): {best_static_model_from_automl.rmse():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00c6ebec-2cfb-4346-8e9c-18fba0276b82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predictions_static_model = best_static_model_from_automl.predict(new_h2o_frame).as_data_frame()\n",
    "display(predictions_static_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d907b14-1391-49f0-b68f-c248002b20e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 예시 코드: 앙상블 예측\n",
    "predictions_full_model = best_model.predict(new_h2o_frame).as_data_frame()\n",
    "predictions_static_model = best_static_model_from_automl.predict(new_h2o_frame).as_data_frame()\n",
    "\n",
    "# 두 예측 결과의 컬럼 이름을 통일 (예: predict)\n",
    "predictions_full_model.columns = ['predict_full']\n",
    "predictions_static_model.columns = ['predict_static']\n",
    "\n",
    "# pandas DataFrame으로 결합\n",
    "combined_predictions_df = pd.concat([predictions_full_model, predictions_static_model], axis=1)\n",
    "\n",
    "# 가중 평균 (예: 80%는 풀 모델, 20%는 정적 모델의 영향)\n",
    "weight_full = 0.6\n",
    "weight_static = 0.4\n",
    "combined_predictions_df['predict_ensemble'] = (\n",
    "    weight_full * combined_predictions_df['predict_full'] +\n",
    "    weight_static * combined_predictions_df['predict_static']\n",
    ")\n",
    "\n",
    "# 최종 결과 df에 결합하여 확인\n",
    "result_df_ensemble = pd.concat([new_data_pandas_df, combined_predictions_df[['predict_ensemble']]], axis=1)\n",
    "print(\"\\n--- 앙상블 예측 결과 (정적 피처 모델 포함) ---\")\n",
    "display(result_df_ensemble)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) H2O AutoML",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
